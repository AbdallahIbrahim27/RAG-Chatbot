# mini-rag

This is a minimal implementation of the RAG model for question answering.

## ğŸ“ Project Structure

### Folder Organization

```
learning-mini-rag/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ routes/              # API Endpoints Layer
â”‚   â”œâ”€â”€ controllers/         # Business Logic Layer
â”‚   â”œâ”€â”€ models/              # Database Layer
â”‚   â”œâ”€â”€ stores/              # External Service Abstractions
â”‚   â”‚   â”œâ”€â”€ llm/            # LLM Provider Integration
â”‚   â”‚   â””â”€â”€ vectordb/       # Vector Database Integration
â”‚   â”œâ”€â”€ helpers/            # Utility Functions
â”‚   â””â”€â”€ assets/             # File & Database Storage
â”œâ”€â”€ docker/                 # Docker Configuration
â””â”€â”€ .vscode/                # Editor Settings
```

### Detailed Folder Breakdown

#### **1. ğŸ“¡ `routes/` - API Endpoints Layer**
Defines all HTTP endpoints that users interact with.

- `base.py` - Basic endpoints (welcome/health check)
- `data.py` - File upload & processing endpoints
- `nlp.py` - NLP operations (indexing, search, RAG answers)
- `schemes/` - Request/response validation models

**Example:** `POST /api/v1/data/upload/{project_id}` â†’ handled by `routes/data.py`

---

#### **2. ğŸ® `controllers/` - Business Logic Layer**
Contains core business logic and orchestrates operations between API and database.

- `BaseController.py` - Shared utilities for all controllers
- `ProjectController.py` - Manages project folder creation
- `DataController.py` - File validation and path generation
- `ProcessController.py` - Document loading and chunking (uses LangChain)
- `NLPController.py` - **RAG orchestration** (embedding, indexing, search, answer generation)

**Example:** `NLPController` takes a question â†’ retrieves relevant chunks â†’ builds prompt â†’ calls LLM

---

#### **3. ğŸ’¾ `models/` - Database Layer**
Handles all database operations (CRUD) and schema definitions.

**Structure:**
```
models/
â”œâ”€â”€ ProjectModel.py       # Project CRUD operations
â”œâ”€â”€ AssetModel.py         # File asset CRUD operations  
â”œâ”€â”€ ChunkModel.py         # Document chunks CRUD operations
â”œâ”€â”€ db_schemes/           # Data schemas (structure definitions)
â”‚   â”œâ”€â”€ project.py
â”‚   â”œâ”€â”€ asset.py
â”‚   â””â”€â”€ data_chunk.py
â””â”€â”€ enums/                # Enumerations (constants)
```

**Example:** `ChunkModel.insert_many_chunks()` saves text chunks to MongoDB in batches

---

#### **4. ğŸ¤– `stores/llm/` - LLM Provider Abstraction**
Manages LLM integrations (OpenAI, Cohere) with a unified interface.

**Structure:**
```
stores/llm/
â”œâ”€â”€ LLMInterface.py              # Abstract interface (contract)
â”œâ”€â”€ LLMProviderFactory.py        # Creates provider instances
â”œâ”€â”€ LLMEnums.py                  # Provider types, roles
â”œâ”€â”€ providers/
â”‚   â”œâ”€â”€ OpenAIProvider.py        # OpenAI implementation
â”‚   â””â”€â”€ CoHereProvider.py        # Cohere implementation
â””â”€â”€ templates/                   # Prompt templates
    â”œâ”€â”€ template_parser.py       # Multi-language template loader
    â””â”€â”€ locales/
        â”œâ”€â”€ en/rag.py           # English RAG prompts
        â””â”€â”€ ar/rag.py           # Arabic RAG prompts
```

**Example:** Factory creates OpenAI client â†’ generates embeddings â†’ creates chat completion

---

#### **5. ğŸ—„ï¸ `stores/vectordb/` - Vector Database Abstraction**
Manages vector database operations (currently Qdrant).

**Structure:**
```
stores/vectordb/
â”œâ”€â”€ VectorDBInterface.py         # Abstract interface
â”œâ”€â”€ VectorDBProviderFactory.py   # Creates DB client
â”œâ”€â”€ VectorDBEnums.py             # DB types, distance metrics
â””â”€â”€ providers/
    â””â”€â”€ QdrantDBProvider.py      # Qdrant implementation
```

**Example:** Stores chunk embeddings â†’ Performs semantic search by cosine similarity

---

#### **6. âš™ï¸ `helpers/` - Utility Functions**
Provides shared helper functions used across the application.

- `config.py` - Loads `.env` settings into Pydantic model

**Example:** `get_settings()` returns all configuration (API keys, database URLs, model IDs)

---

#### **7. ğŸ“¦ `assets/` - File Storage**
Stores uploaded files and database files.

**Structure:**
```
assets/
â”œâ”€â”€ files/                  # Uploaded documents organized by project
â”‚   â””â”€â”€ {project_id}/      # Each project has its own folder
â”œâ”€â”€ database/              # Vector database storage (Qdrant)
â”‚   â””â”€â”€ qdrant_db/
â””â”€â”€ *.postman_collection.json  # API testing collections
```

**Example:** Uploaded file saved as `assets/files/1/abc123_resume.pdf`

---

### ğŸ”„ RAG Pipeline Flow

```
1. Upload        â†’ POST /data/upload/{project_id}
                   (User uploads PDF/TXT)
                   â†“
2. Process       â†’ POST /data/process/{project_id}
                   (File chunked using LangChain)
                   â†“
3. Embed & Index â†’ POST /nlp/index/push/{project_id}
                   (Chunks embedded and stored in Qdrant)
                   â†“
4. Query         â†’ POST /nlp/index/answer/{project_id}
                   (User asks a question)
                   â†“
5. Retrieve      â†’ Semantic search finds relevant chunks
                   â†“
6. Augment       â†’ Retrieved chunks added to prompt template
                   â†“
7. Generate      â†’ LLM generates answer with context
```

---

### ğŸ“Š How Components Work Together

```
User Request (API)
    â†“
[routes/]          â† Receives HTTP request
    â†“
[controllers/]     â† Processes business logic
    â†“
[models/]          â† Reads/writes to MongoDB
[stores/llm/]      â† Calls OpenAI/Cohere APIs
[stores/vectordb/] â† Searches Qdrant vector DB
    â†“
[helpers/]         â† Provides config & utilities
    â†“
Response sent back to user
```

---

### ğŸ¯ Responsibility Summary

| Folder | Responsibility | Example |
|--------|---------------|---------|
| **routes/** | API endpoints (HTTP layer) | `POST /upload` |
| **controllers/** | Business logic (orchestration) | Validate file â†’ chunk â†’ embed |
| **models/** | Database operations (data layer) | Save 100 chunks to MongoDB |
| **stores/llm/** | AI provider integration | Call OpenAI to get embeddings |
| **stores/vectordb/** | Vector database operations | Search Qdrant for similar docs |
| **helpers/** | Configuration & utilities | Load `.env` settings |
| **assets/** | File & database storage | Store uploaded PDFs |

---

## Requirements

* Python 3.8 or later

#### Install Python using MiniConda

1. Download and install MiniConda from [here](https://docs.anaconda.com/free/miniconda/#quick-command-line-install)
2. Create a new environment using the following command:

```bash
$ conda create -n mini-rag python=3.8
```

3. Activate the environment:

```bash
$ conda activate mini-rag
```

### (Optional) Setup you command line interface for better readability

```bash
export PS1="\[\033[01;32m\]\u@\h:\w\n\[\033[00m\]\$ "
```

## Installation

### Install the required packages

```bash
$ pip install -r requirements.txt
```

### Setup the environment variables

```bash
$ cp .env.example .env
```

Set your environment variables in the `.env` file. Like `OPENAI_API_KEY` value.

## Run Docker Compose Services

```bash
$ cd docker
$ cp .env.example .env
```

* update `.env` with your credentials

```bash
$ cd docker
$ sudo docker compose up -d
```

## Run the FastAPI server

```bash
$ uvicorn main:app --reload --host 0.0.0.0 --port 5000
```

## API Endpoints

### Base Endpoints
- `GET /api/v1/` - Welcome endpoint

### Data Endpoints
- `POST /api/v1/data/upload/{project_id}` - Upload files (PDF/TXT)
- `POST /api/v1/data/process/{project_id}` - Process files into chunks

### NLP Endpoints
- `POST /api/v1/nlp/index/push/{project_id}` - Index chunks into vector DB
- `GET /api/v1/nlp/index/info/{project_id}` - Get collection info
- `POST /api/v1/nlp/index/search/{project_id}` - Semantic search
- `POST /api/v1/nlp/index/answer/{project_id}` - RAG question answering

## POSTMAN Collection

Download the POSTMAN collection from `/assets/mini-rag-app.postman_collection.json`

## About

Learning mini-rag course - A step-by-step educational project to build a production-ready RAG application.